{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 1)) (1.25.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: pdfplumber in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 4)) (0.11.5)\n",
      "Requirement already satisfied: llama_parser in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: chromadb==0.6.3 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: huggingface-hub==0.27.1 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 7)) (0.27.1)\n",
      "Collecting numpy==1.24.3 (from -r /data/jung/src/requirements.txt (line 8))\n",
      "  Obtaining dependency information for numpy==1.24.3 from https://files.pythonhosted.org/packages/6f/72/38f9a536bdb5bfb1682f2520f133ec6e08dde8bcca1f632e347641d90763/numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: openai==1.59.7 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 9)) (1.59.7)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: langchain==0.3.14 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 14)) (0.3.14)\n",
      "Requirement already satisfied: langchain-community==0.3.14 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 15)) (0.3.14)\n",
      "Requirement already satisfied: langchain-core==0.3.29 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 16)) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.5 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 17)) (0.3.5)\n",
      "Requirement already satisfied: langsmith==0.2.10 in /opt/conda/lib/python3.10/site-packages (from -r /data/jung/src/requirements.txt (line 18)) (0.2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r /data/jung/src/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r /data/jung/src/requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->-r /data/jung/src/requirements.txt (line 2)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r /data/jung/src/requirements.txt (line 2)) (2024.12.14)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /opt/conda/lib/python3.10/site-packages (from pdfplumber->-r /data/jung/src/requirements.txt (line 4)) (20231228)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from pdfplumber->-r /data/jung/src/requirements.txt (line 4)) (4.30.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.10.5)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.115.6)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.8.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.10.14)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (13.9.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.27.1->-r /data/jung/src/requirements.txt (line 7)) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.27.1->-r /data/jung/src/requirements.txt (line 7)) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.27.1->-r /data/jung/src/requirements.txt (line 7)) (24.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.59.7->-r /data/jung/src/requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.59.7->-r /data/jung/src/requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.59.7->-r /data/jung/src/requirements.txt (line 9)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai==1.59.7->-r /data/jung/src/requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.3->-r /data/jung/src/requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.3->-r /data/jung/src/requirements.txt (line 10)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.3->-r /data/jung/src/requirements.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (3.11.11)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (2.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core==0.3.29->-r /data/jung/src/requirements.txt (line 16)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith==0.2.10->-r /data/jung/src/requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber->-r /data/jung/src/requirements.txt (line 4)) (41.0.3)\n",
      "Requirement already satisfied: llama-index<0.10.0,>=0.9.40 in /opt/conda/lib/python3.10/site-packages (from llama_parser->-r /data/jung/src/requirements.txt (line 5)) (0.9.48)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (1.18.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.59.7->-r /data/jung/src/requirements.txt (line 9)) (1.0.4)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.41.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.29->-r /data/jung/src/requirements.txt (line 16)) (2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.9)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (3.9.1)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (0.8.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (24.12.23)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (5.29.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.11.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14->-r /data/jung/src/requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (14.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->-r /data/jung/src/requirements.txt (line 4)) (1.15.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index<0.10.0,>=0.9.40->llama_parser->-r /data/jung/src/requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14->-r /data/jung/src/requirements.txt (line 15)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->-r /data/jung/src/requirements.txt (line 4)) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.6.3->-r /data/jung/src/requirements.txt (line 6)) (0.6.1)\n",
      "Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "faiss-cpu 1.9.0.post1 requires numpy<3.0,>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r \"/data/jung/src/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/path/to/jung')  # 정확한 경로를 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from pdf_parsing.upstage_parser import parsing\n",
    "from pdf_parsing.make_md_and_summaries import make_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /data/jung/src\n",
      "Folders in current directory: ['VectorDB', 'requirements.txt', 'pdf_parsing', 'embedding_models', 'README.md', '=0.26.0', 'QA_model', 'datas', 'sample.ipynb', '.env', 'pdfs']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Folders in current directory:\", os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdfs/크래프톤_대신증권(2024.12.24).pdf\n",
      "pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "pdfs/크래프톤_교보증권(2024.7.23).pdf\n",
      "\n",
      "\n",
      "target data : pdfs/크래프톤_SK증권(2024.10.18).pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_routes = glob('pdfs/*')\n",
    "for i in range(3):\n",
    "    print(data_routes[i])\n",
    "route = data_routes[1] # 예시로 pdf문서 한개를 parsing 후 데이터를 추출합니다.\n",
    "print('\\n')\n",
    "print('target data :', route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크래프톤_SK증권(2024.10.18).json 파일이 이미 존재합니다. 기존 파일을 불러옵니다.\n",
      "route: pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Cropping box: (40.065036, 396.27792, 104.300064, 509.20703999999995) on page 1 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png\n",
      "Cropping box: (35.659668, 502.94918399999995, 179.36991600000002, 612.8473919999999) on page 1 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_1_id_9_image.png\n",
      "Cropping box: (35.600136, 603.0534719999999, 179.01272400000002, 708.910464) on page 1 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_1_id_11_image.png\n",
      "Cropping box: (41.553336, 710.31408, 177.94114800000003, 834.019776) on page 1 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_1_id_20_image.png\n",
      "Cropping box: (192.22882800000002, 679.584, 566.9827680000001, 838.6503359999999) on page 1 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_1_id_21_image.png\n",
      "Cropping box: (66.9735, 152.457888, 528.703692, 542.1261119999999) on page 2 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_2_id_23_image.png\n",
      "Cropping box: (69.65244000000001, 561.125856, 527.274924, 652.165056) on page 2 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_2_id_26_image.png\n",
      "Cropping box: (68.580864, 671.8383359999999, 526.3819440000001, 761.025312) on page 2 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_2_id_29_image.png\n",
      "Cropping box: (205.325868, 137.38752, 527.9297760000001, 290.223648) on page 3 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_3_id_33_image.png\n",
      "Cropping box: (204.43288800000002, 308.213088, 520.428744, 509.2912319999999) on page 3 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_3_id_36_image.png\n",
      "Cropping box: (81.201648, 539.2359359999999, 272.18030400000004, 715.814208) on page 3 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_3_id_39_image.png\n",
      "Cropping box: (322.842036, 538.814976, 512.27286, 715.2248639999999) on page 3 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_3_id_42_image.png\n",
      "Cropping box: (67.50928800000001, 153.21561599999998, 281.229168, 318.42796799999996) on page 4 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_4_id_46_image.png\n",
      "Cropping box: (315.341004, 151.70016, 526.8582, 317.922816) on page 4 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_4_id_48_image.png\n",
      "Cropping box: (70.42635600000001, 378.34502399999997, 523.28628, 633.558624) on page 4 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_4_id_52_image.png\n",
      "Cropping box: (56.436336000000004, 145.301568, 295.81450800000005, 456.755424) on page 5 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_5_id_57_image.png\n",
      "Cropping box: (55.543356, 447.04569599999996, 294.6834, 760.1833919999999) on page 5 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_5_id_59_image.png\n",
      "Cropping box: (304.446648, 146.059296, 541.800732, 451.11456) on page 5 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_5_id_62_image.png\n",
      "Cropping box: (305.87541600000003, 446.96150399999993, 541.979328, 761.614656) on page 5 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_5_id_64_image.png\n",
      "Cropping box: (91.02442800000001, 419.93587199999996, 304.08945600000004, 601.902432) on page 6 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_6_id_66_image.png\n",
      "Cropping box: (318.615264, 452.2656, 522.3933000000001, 609.311328) on page 6 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_6_id_67_image.png\n",
      "Cropping box: (96.501372, 702.4842239999999, 523.0481520000001, 751.0064639999999) on page 6 of pdfs/크래프톤_SK증권(2024.10.18).pdf\n",
      "Image saved to: datas/크래프톤_SK증권(2024.10.18)/page_6_id_70_image.png\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = 'datas' # 결과물을 저장할 폴더를 지정합니다.\n",
    "\n",
    "result = parsing(BASE_DIR, route) # route는 parsing할 pdf의 경로입니다.\n",
    "# 이미 parsing한 json파일이 있는 경우, 기존 결과물을 불러와 summaries를 만듭니다.\n",
    "summaries = make_md(BASE_DIR, route, result['elements'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5,\n",
       "  'type': 'figure',\n",
       "  'image_route': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png',\n",
       "  'dir_route': 'datas/크래프톤_SK증권(2024.10.18)',\n",
       "  'file_name': '크래프톤_SK증권(2024.10.18).pdf',\n",
       "  'page': 1,\n",
       "  'investment': 'SK증권(2024.10.18)',\n",
       "  'company_name': '크래프톤',\n",
       "  'summary': '죄송하지만, 이미지를 분석하거나 요약할 수 없습니다. 다른 질문이나 요청이 있으시면 도와드리겠습니다!'},\n",
       " {'id': 9,\n",
       "  'type': 'table',\n",
       "  'image_route': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_9_image.png',\n",
       "  'dir_route': 'datas/크래프톤_SK증권(2024.10.18)',\n",
       "  'file_name': '크래프톤_SK증권(2024.10.18).pdf',\n",
       "  'page': 1,\n",
       "  'investment': 'SK증권(2024.10.18)',\n",
       "  'company_name': '크래프톤',\n",
       "  'table': '| Company Data          |        |\\n|-----------------------|--------|\\n| 발행주식수             | 4,790 만주 |\\n| 시가총액               | 16,022 십억원 |\\n| 주요주주               |        |\\n| 장병규(외31)          | 21.29% |\\n| IMAGE FRAME INVESTMENT(HK) | 13.87% |',\n",
       "  'summary': '\\n\\n크래프톤의 발행주식수는 4,790만주이며, 시가총액은 16,022십억원입니다. 주요주주로는 장병규가 21.29%, IMAGE FRAME INVESTMENT(HK)가 13.87%의 지분을 보유하고 있습니다.'},\n",
       " {'id': 11,\n",
       "  'type': 'table',\n",
       "  'image_route': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_11_image.png',\n",
       "  'dir_route': 'datas/크래프톤_SK증권(2024.10.18)',\n",
       "  'file_name': '크래프톤_SK증권(2024.10.18).pdf',\n",
       "  'page': 1,\n",
       "  'investment': 'SK증권(2024.10.18)',\n",
       "  'company_name': '크래프톤',\n",
       "  'table': '| Stock Data            |        |\\n|-----------------------|--------|\\n| 주가(24/10/17)       | 334,500 원 |\\n| KOSPI                 | 2,609.30 pt |\\n| 52주 최고가          | 349,000 원 |\\n| 52주 최저가          | 153,000 원 |\\n| 60일 평균 거래대금   | 44 십억원  |',\n",
       "  'summary': '\\n\\n크래프톤의 주식 데이터는 현재 주가, KOSPI 지수, 52주 최고 및 최저가, 60일 평균 거래대금을 포함하고 있습니다.'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[:3]\n",
    "# 아래처럼 type별로 정보를 담아 return합니다.\n",
    "# table의 경우 table이 추가로 담깁니다.\n",
    "# element의 내용들은 pdf의 이름.md 형태로 저장됩니다.\n",
    "# summaries는 pdf의 이름.csv로 저잘됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_shape : 1024\n",
      "[-0.91503906, -0.06335449, -0.90283203, -0.3083496, -0.7163086, -1.6240234, -0.89160156, -1.2597656, 0.03729248, 0.22106934]\n"
     ]
    }
   ],
   "source": [
    "from embedding_models.navercloud_embedding import get_text_embedding\n",
    "test_text = '안녕하세요. 저는 용가리입니다.'\n",
    "embedding_vectors = get_text_embedding(test_text)\n",
    "print('vector_shape :', len(embedding_vectors)) # 1024 길이의 임베딩 벡터가 생성됩니다.\n",
    "print(embedding_vectors[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.12.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.45.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누락된 이미지 파일 5개:\n",
      "1. \n",
      "2. \n",
      "3. \n",
      "4. \n",
      "5. \n",
      "CSV 로드 완료! 총 27 개의 요소를 RAG에 등록했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# CSV 경로 설정\n",
    "csv_path = \"/data/jung/src/datas/크래프톤_SK증권(2024.10.18)/크래프톤_SK증권(2024.10.18).csv\"\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(csv_path, keep_default_na=False)  # NaN 대신 빈 문자열 처리\n",
    "\n",
    "missing_images = []\n",
    "for image_path in df['image_route']:\n",
    "    if not pd.isna(image_path):  # 이미지 경로가 비어있지 않은 경우\n",
    "        if not os.path.exists(image_path):  # 파일 존재 여부 확인\n",
    "            missing_images.append(image_path)\n",
    "\n",
    "# 결과 출력\n",
    "if missing_images:\n",
    "    print(f\"누락된 이미지 파일 {len(missing_images)}개:\")\n",
    "    for idx, path in enumerate(missing_images, 1):\n",
    "        print(f\"{idx}. {path}\")\n",
    "else:\n",
    "    print(\"모든 이미지 파일이 존재합니다.\")\n",
    "\n",
    "# rag_data 형태로 변환\n",
    "# 필요한 컬럼: id, type, image_route, summary, original_content 등\n",
    "rag_data = []\n",
    "for idx, row in df.iterrows():\n",
    "    # row[\"type\"]가 figure/table/paragraph 등\n",
    "    item = {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        # CSV상의 image_route 필드 (예: datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png)\n",
    "        \"image_path\": row[\"image_route\"] if row[\"image_route\"] else None,\n",
    "        \"summary\": row[\"summary\"],            # 이미지/텍스트 요약\n",
    "        \"original_content\": row[\"original_content\"],  # paragraph의 원문(HTML 등)\n",
    "    }\n",
    "    rag_data.append(item)\n",
    "\n",
    "print(f\"CSV 로드 완료! 총 {len(rag_data)} 개의 요소를 RAG에 등록했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 로드 완료! 총 27 개의 요소를 RAG에 등록했습니다.\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png, 사이즈: (446, 784)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_1_id_9_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_1_id_9_image.png, 사이즈: (998, 763)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_1_id_11_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_1_id_11_image.png, 사이즈: (996, 735)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_1_id_20_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_1_id_20_image.png, 사이즈: (947, 859)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_1_id_21_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_1_id_21_image.png, 사이즈: (2602, 1104)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_2_id_23_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_2_id_23_image.png, 사이즈: (3207, 2706)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_2_id_26_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_2_id_26_image.png, 사이즈: (3178, 632)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_2_id_29_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_2_id_29_image.png, 사이즈: (3179, 619)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_3_id_33_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_3_id_33_image.png, 사이즈: (2240, 1061)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_3_id_36_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_3_id_36_image.png, 사이즈: (2194, 1396)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_3_id_39_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_3_id_39_image.png, 사이즈: (1326, 1226)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_3_id_42_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_3_id_42_image.png, 사이즈: (1315, 1225)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_4_id_46_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_4_id_46_image.png, 사이즈: (1484, 1147)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_4_id_48_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_4_id_48_image.png, 사이즈: (1469, 1154)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_4_id_52_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_4_id_52_image.png, 사이즈: (3145, 1772)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_5_id_57_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_5_id_57_image.png, 사이즈: (1662, 2163)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_5_id_59_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_5_id_59_image.png, 사이즈: (1661, 2175)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_5_id_62_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_5_id_62_image.png, 사이즈: (1648, 2118)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_5_id_64_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_5_id_64_image.png, 사이즈: (1639, 2185)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_6_id_66_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_6_id_66_image.png, 사이즈: (1479, 1263)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_6_id_67_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_6_id_67_image.png, 사이즈: (1415, 1090)\n",
      "이미지 경로: datas/크래프톤_SK증권(2024.10.18)/page_6_id_70_image.png\n",
      "이미지 열기 성공: datas/크래프톤_SK증권(2024.10.18)/page_6_id_70_image.png, 사이즈: (2962, 337)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# CSV 경로 설정 => 각 절대경로의 CSV 에 있는 폴더로 지정하면 이후 동적으로 어느정도 대응하게 함\n",
    "csv_path = \"/data/jung/src/datas/크래프톤_SK증권(2024.10.18)/크래프톤_SK증권(2024.10.18).csv\"\n",
    "\n",
    "# 기본 디렉토리 설정\n",
    "base_dir = os.path.dirname(csv_path)\n",
    "\n",
    "# 이미지 경로 생성 함수\n",
    "def get_full_image_path(image_route):\n",
    "    \"\"\"\n",
    "    경로 중복 문제를 해결하기 위해 base_dir와 image_route를 조합.\n",
    "    image_route가 이미 base_dir를 포함하면 그대로 반환.\n",
    "    \"\"\"\n",
    "    # 절대 경로인지 확인\n",
    "    if os.path.isabs(image_route):\n",
    "        return image_route\n",
    "    # base_dir 중복 제거\n",
    "    full_path = os.path.normpath(os.path.join(base_dir, image_route))\n",
    "    if base_dir in full_path:\n",
    "        # 중복된 base_dir 제거\n",
    "        return full_path.replace(base_dir + \"/\", \"\", 1)\n",
    "    return full_path\n",
    "\n",
    "# CSV 데이터 로드\n",
    "df = pd.read_csv(csv_path, keep_default_na=False)\n",
    "\n",
    "# RAG 데이터 생성\n",
    "rag_data = []\n",
    "for idx, row in df.iterrows():\n",
    "    # 이미지 절대 경로 생성\n",
    "    image_path = get_full_image_path(row[\"image_route\"]) if row[\"image_route\"] else None\n",
    "    item = {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"type\": row[\"type\"],\n",
    "        \"image_path\": image_path,  # 절대 경로\n",
    "        \"summary\": row[\"summary\"],\n",
    "        \"original_content\": row[\"original_content\"],\n",
    "    }\n",
    "    rag_data.append(item)\n",
    "\n",
    "print(f\"CSV 로드 완료! 총 {len(rag_data)} 개의 요소를 RAG에 등록했습니다.\")\n",
    "\n",
    "# 이미지 경로 확인 및 로드 테스트\n",
    "for item in rag_data:\n",
    "    if item[\"image_path\"]:\n",
    "        try:\n",
    "            print(f\"이미지 경로: {item['image_path']}\")\n",
    "            raw_image = Image.open(item[\"image_path\"])\n",
    "            raw_image.load()\n",
    "            print(f\"이미지 열기 성공: {item['image_path']}, 사이즈: {raw_image.size}\")\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 열기 실패: {item['image_path']}, 오류: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rag_search(question: str, data_list, top_k=3):\n",
    "    \"\"\"\n",
    "    - 질문(문자열)을 토대로 data_list에서 가장 관련 있을 것 같은 항목을 찾아온다.\n",
    "    - 여기서는 아주 단순하게 \"질문 내 단어가 item['summary'] or item['original_content']에 몇 번 등장하느냐\"를 점수로 사용.\n",
    "    - 실제 서비스에선 BM25, TF-IDF, 혹은 Embedding-based 검색으로 교체하는 것이 좋음.\n",
    "    \"\"\"\n",
    "    q_lower = question.lower().split()\n",
    "    \n",
    "    # 각 항목을 순회하며 점수 계산\n",
    "    scored = []\n",
    "    for item in data_list:\n",
    "        text_for_search = f\"{item['summary']} {item['original_content']}\".lower()\n",
    "        score = 0\n",
    "        for token in q_lower:\n",
    "            if token in text_for_search:\n",
    "                score += 1\n",
    "        scored.append((score, item))\n",
    "    \n",
    "    # 점수 내림차순 정렬 후 상위 top_k 추출\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    top_items = [s[1] for s in scored[:top_k] if s[0] > 0]  # score>0인 것만\n",
    "    return top_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# NLTK 데이터 다운로드 (최초 실행 시 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def bm25_rag_search(question: str, data_list, top_k=3):\n",
    "    \"\"\"\n",
    "    - BM25 알고리즘을 사용해 data_list에서 질문과 가장 관련 있는 항목을 찾아온다.\n",
    "    - BM25는 'rank_bm25' 라이브러리를 사용.\n",
    "    - 각 데이터의 'summary'와 'original_content'를 기준으로 검색 수행.\n",
    "    \"\"\"\n",
    "    # 각 데이터에서 'summary'와 'original_content'를 결합하여 검색 대상 문서 생성\n",
    "    corpus = [f\"{item['summary']} {item['original_content']}\" for item in data_list]\n",
    "    \n",
    "    # 토큰화\n",
    "    tokenized_corpus = [word_tokenize(doc.lower()) for doc in corpus]\n",
    "    \n",
    "    # BM25 객체 생성\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    # 질문도 토큰화\n",
    "    tokenized_question = word_tokenize(question.lower())\n",
    "    \n",
    "    # BM25 점수 계산\n",
    "    scores = bm25.get_scores(tokenized_question)\n",
    "    \n",
    "    # 점수와 데이터 항목 연결\n",
    "    scored = list(zip(scores, data_list))\n",
    "    \n",
    "    # 점수 내림차순 정렬 후 상위 top_k 추출\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    top_items = [item for score, item in scored[:top_k] if score > 0]  # score>0인 것만 반환\n",
    "    \n",
    "    return top_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "model_id = \"beomi/Llama-3-KoEn-8B-xtuner-llava-preview\"\n",
    "\n",
    "# 모델 로드 (GPU 사용, 8bit or 4bit 로드 등 필요 시 수정)\n",
    "\"\"\"\n",
    "revision = 그 비전쪽 모델 참고\n",
    "v1. revision='a38aac3': Basic ChatVector, with 25B+ trained KoEn ckpt(rev. d4d25a2).\n",
    "\n",
    "v1-1. revision='0224971': Basic ChatVector, with 40B+ trained KoEn ckpt(rev. ad39b32).\n",
    "\n",
    "v1-2. revision='170746c': Basic ChatVector, with 80B+ trained KoEn ckpt(rev. b4c45ab).\n",
    "\n",
    "v2. revision='4f04d1e': Model diff based merging(ref. https://huggingface.co/blog/maywell/llm-feature-transfer), with 25B+ trained KoEn ckpt(rev. d4d25a2).\n",
    "\"\"\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto',\n",
    "    revision='4f04d1e',  # 예: '4f04d1e' for basic ChatVector\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = processor.tokenizer\n",
    "# 모델이 eos_token_id로 아래 토큰들을 사용하므로, generate할 때 필요\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "print(\"모델 로드 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy is installed. Version: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"NumPy is installed. Version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 사이즈: (795, 735)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raw_image = Image.open(image_path)\n",
    "    raw_image.load()  # 실제 로드\n",
    "    print(\"이미지 사이즈:\", raw_image.size)\n",
    "except Exception as e:\n",
    "    print(f\"이미지 열기 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n"
     ]
    }
   ],
   "source": [
    "print(raw_image.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (795, 735), mode: RGB\n",
      "Image size: (795, 735), mode: RGB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    image_path = \"/data/jung/src/recovered_image.png\"\n",
    "    raw_image = Image.open(image_path)\n",
    "    print(f\"Image size: {raw_image.size}, mode: {raw_image.mode}\")\n",
    "    raw_image = raw_image.convert(\"RGB\")\n",
    "    print(f\"Image size: {raw_image.size}, mode: {raw_image.mode}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: {'pixel_values': tensor([[[[ 0.7041, -1.1207, -1.1207,  ...,  1.3756,  1.3756,  1.3756],\n",
      "          [ 0.8938, -0.4200, -0.4200,  ...,  1.3756,  1.3756,  1.3756],\n",
      "          [ 0.7041, -1.1499, -1.2083,  ...,  1.3756,  1.3756,  1.3756],\n",
      "          ...,\n",
      "          [ 1.9303,  0.4851,  0.6311,  ...,  1.9303,  1.9303,  1.9303],\n",
      "          [-0.3762, -0.4492,  1.0982,  ...,  1.9303,  1.9303,  1.9303],\n",
      "          [ 1.1128,  1.9303,  1.8719,  ...,  1.9303,  1.9303,  1.9303]],\n",
      "\n",
      "         [[ 0.8142, -1.0617, -1.0617,  ...,  1.5046,  1.5046,  1.5046],\n",
      "          [ 1.0093, -0.3414, -0.3414,  ...,  1.5046,  1.5046,  1.5046],\n",
      "          [ 0.8142, -1.0918, -1.1518,  ...,  1.5046,  1.5046,  1.5046],\n",
      "          ...,\n",
      "          [ 2.0749,  0.5891,  0.7392,  ...,  2.0749,  2.0749,  2.0749],\n",
      "          [-0.2963, -0.3714,  1.2194,  ...,  2.0749,  2.0749,  2.0749],\n",
      "          [ 1.2344,  2.0749,  2.0149,  ...,  2.0749,  2.0749,  2.0749]],\n",
      "\n",
      "         [[ 0.9514, -0.8261, -0.8261,  ...,  1.6055,  1.6055,  1.6055],\n",
      "          [ 1.1363, -0.1435, -0.1435,  ...,  1.6055,  1.6055,  1.6055],\n",
      "          [ 0.9514, -0.8545, -0.9114,  ...,  1.6055,  1.6055,  1.6055],\n",
      "          ...,\n",
      "          [ 2.1459,  0.7381,  0.8803,  ...,  2.1459,  2.1459,  2.1459],\n",
      "          [-0.1009, -0.1720,  1.3354,  ...,  2.1459,  2.1459,  2.1459],\n",
      "          [ 1.3496,  2.1459,  2.0890,  ...,  2.1459,  2.1459,  2.1459]]]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPImageProcessor\n",
    "\n",
    "image_processor = CLIPImageProcessor()\n",
    "try:\n",
    "    processed_image = image_processor(images=raw_image, return_tensors=\"pt\")\n",
    "    print(\"Processed image:\", processed_image)\n",
    "except Exception as e:\n",
    "    print(f\"CLIPImageProcessor error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rag_multimodal_qa(question: str, data_list, top_k=3):\n",
    "    \"\"\"\n",
    "    1) simple_rag_search로 관련 항목 top_k 검색\n",
    "    2) 해당 텍스트와 (가능하면) 이미지 1개를 모델에 전달\n",
    "    3) 답변 생성\n",
    "    4) \"질문 / 대답\" 형태로 리턴\n",
    "    \"\"\"\n",
    "    # 1) RAG 검색\n",
    "    # relevant_items = simple_rag_search(question, data_list, top_k=top_k)\n",
    "    relevant_items = bm25_rag_search(question, data_list, top_k=top_k)\n",
    "    if not relevant_items:\n",
    "        # 검색된 결과가 없다면\n",
    "        return f\"질문 : {question}\\n대답 : 관련된 자료(텍스트/이미지)를 찾지 못했습니다.\"\n",
    "\n",
    "    # 2) 프롬프트 구성\n",
    "    #    LLaVA 계열(ChatVector) 형식에 맞춰서:\n",
    "    #    <|start_header_id|>user<|end_header_id|>\\n\\n<image>\\n{...}\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{...}\n",
    "    \n",
    "    # 우선 \"답변하기 전, RAG에서 가져온 텍스트\"를 간단히 붙여줄 수도 있고,\n",
    "    # 이미지가 있을 경우 <image> 토큰으로 모델에 이미지 주입.\n",
    "    \n",
    "    # 여기서는 \"첫 번째 이미지\"가 있으면 모델에 넣고, \n",
    "    # 나머지 텍스트/표 요약은 prompt에 그대로 추가하는 방식(아주 단순).\n",
    "    \n",
    "    context_texts = []\n",
    "    image_path = None\n",
    "\n",
    "    for item in relevant_items:\n",
    "        # 최대 1개 이미지만\n",
    "        if image_path is None and item[\"type\"] in [\"figure\", \"table\"] and item[\"image_path\"]:\n",
    "            # table도 사실 이미지로 크롭되어 있으면 figure처럼 넣을 수도 있음\n",
    "            # 사용자가 \"table=이미지\"로 저장한 것이므로, model에는 이미지로 전달 가능\n",
    "            if os.path.exists(item[\"image_path\"]):\n",
    "                image_path = item[\"image_path\"]\n",
    "            else:\n",
    "                print(f\"이미지 파일이 없습니다: {item['image_path']}\")\n",
    "\n",
    "        # 텍스트 요약 + 원문 중에서 길이가 좀 있는 것이면 prompt에 포함\n",
    "        # (여기서는 summary만 사용, 필요하면 original_content도 추가)\n",
    "        if item[\"summary\"]:\n",
    "            context_texts.append(item[\"summary\"])\n",
    "        elif item[\"original_content\"]:\n",
    "            context_texts.append(item[\"original_content\"])\n",
    "    \n",
    "    # 하나로 합치기\n",
    "    context_joined = \"\\n\".join(context_texts)\n",
    "    # 실제 대화 프롬프트(사용자 질문)\n",
    "    user_prompt = (\n",
    "        f\"아래는 CSV 및 이미지에서 찾은 관련 요약/내용입니다:\\n\"\n",
    "        f\"{context_joined}\\n\\n\"\n",
    "        f\"질문: {question}\\n\"\n",
    "        f\"답변해 주세요.\\n\"\n",
    "    )\n",
    "\n",
    "    # LLaVA 스타일 예시:\n",
    "    # user 영역에 <image> 토큰 + \"설명해주세요\" → assistant가 답변\n",
    "    # 여기서는 실제 \"이미지 내용 설명\" 뿐 아니라, 질문에 대한 대답을 하도록 만들기 위해\n",
    "    # Prompt를 조금 변경할 수 있음\n",
    "\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        # 이미지 존재 시 <image> 포함\n",
    "        prompt = (\n",
    "            \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "            \"<image>\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|eot_id|>\"\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # 이미지 없으면 <image> 없이 텍스트만\n",
    "        prompt = (\n",
    "            \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|eot_id|>\"\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    # 3) 모델 인퍼런스\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        try:\n",
    "            # 이미지 로드 및 RGB 변환\n",
    "            raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "            print(f\"Original image size: {raw_image.size}, mode: {raw_image.mode}\")\n",
    "\n",
    "            # # CLIPImageProcessor 초기화 및 리사이징\n",
    "            # image_processor = CLIPImageProcessor(size=336)\n",
    "            # processed_image = image_processor(images=raw_image, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "            # processed_image = processed_image.to(dtype=torch.float32, device=model.device)\n",
    "            # print(f\"Processed image shape: {processed_image.shape}\")\n",
    "\n",
    "            # # 텍스트와 이미지 통합 입력\n",
    "            # input_ids = processor.tokenizer(prompt, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(model.device)\n",
    "            # inputs = {\"input_ids\": input_ids, \"pixel_values\": processed_image}\n",
    "\n",
    "\n",
    "            # 이미지 자체를 processor로 바로 전달\n",
    "            inputs = processor(\n",
    "                text=prompt,  # 텍스트 입력\n",
    "                images=raw_image,  # Pillow 이미지 객체 전달\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            ).to(model.device, torch.float16)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"이미지 처리 중 오류 발생: {e}\\n이미지 없이 텍스트만 진행합니다.\")\n",
    "            # 텍스트만 진행\n",
    "            inputs = processor(\n",
    "                text=prompt,  # text 키워드 명시\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            ).to(model.device, torch.float16)\n",
    "    else:\n",
    "        inputs = processor(\n",
    "            text=prompt,  # text 키워드 명시\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(model.device, torch.float16)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=400,\n",
    "        do_sample=True,\n",
    "        eos_token_id=terminators,\n",
    "    )\n",
    "\n",
    "    # 4) 결과 디코딩\n",
    "    # 첫 토큰들(혹은 스페셜 토큰) 제외하고 디코딩\n",
    "    # LLaVA 시리즈는 <|eot_id|> 등도 쓸 수 있으나 여기서는 간단히 처리\n",
    "    output_text = processor.decode(output_ids[0], skip_special_tokens=False)\n",
    "\n",
    "    # 필요하다면 <|eot_id|> 이후 잘라낼 수도 있음\n",
    "    # 여기서는 일단 통째로 출력 후, 맨 앞 시스템/유저 문자열 제거\n",
    "    # 아래는 단순 예시:\n",
    "    # LLaVA 출력 포맷상 \"user<|end_header_id|>\\n\\n...\"라는 부분이 있을 수 있으므로\n",
    "    # 적당히 후처리\n",
    "    cleaned_answer = output_text\n",
    "    # 간단히 \"assistant<|end_header_id|>\" 뒷부분을 찾아볼 수도 있음\n",
    "    if \"<|start_header_id|>assistant<|end_header_id|>\" in cleaned_answer:\n",
    "        # 그 뒤를 추출\n",
    "        splitted = cleaned_answer.split(\"<|start_header_id|>assistant<|end_header_id|>\")\n",
    "        if len(splitted) > 1:\n",
    "            cleaned_answer = splitted[-1]\n",
    "    # <|eot_id|> 앞부분까지만\n",
    "    if \"<|eot_id|>\" in cleaned_answer:\n",
    "        splitted = cleaned_answer.split(\"<|eot_id|>\")\n",
    "        cleaned_answer = splitted[0].strip()\n",
    "\n",
    "    cleaned_answer = cleaned_answer.strip()\n",
    "\n",
    "    # 최종 출력 형식\n",
    "    return f\"질문 : {question}\\n대답 : {cleaned_answer}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 5, 'type': 'figure', 'image_path': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_5_image.png', 'summary': '죄송하지만, 이미지를 분석하거나 요약할 수 없습니다. 다른 질문이나 요청이 있으시면 도와드리겠습니다!', 'original_content': ''}]\n"
     ]
    }
   ],
   "source": [
    "print(rag_data[:1])  # 첫 번째 요소 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과: [{'id': 9, 'type': 'table', 'image_path': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_9_image.png', 'summary': '\\n\\n크래프톤의 발행주식수는 4,790만주이며, 시가총액은 16,022십억원입니다. 주요주주로는 장병규가 21.29%, IMAGE FRAME INVESTMENT(HK)가 13.87%의 지분을 보유하고 있습니다.', 'original_content': ''}, {'id': 11, 'type': 'table', 'image_path': 'datas/크래프톤_SK증권(2024.10.18)/page_1_id_11_image.png', 'summary': '\\n\\n크래프톤의 주식 데이터는 현재 주가, KOSPI 지수, 52주 최고 및 최저가, 60일 평균 거래대금을 포함하고 있습니다.', 'original_content': ''}]\n"
     ]
    }
   ],
   "source": [
    "question_text = \"크래프톤의 발행 주식 수는?\"\n",
    "\n",
    "relevant_items = simple_rag_search(question_text, rag_data, top_k=2)\n",
    "print(f\"검색 결과: {relevant_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/data/ephemeral/home/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m question_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m크래프톤의 발행 주식 수는?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrag_multimodal_qa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrag_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mrag_multimodal_qa\u001b[0;34m(question, data_list, top_k)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m1) simple_rag_search로 관련 항목 top_k 검색\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m2) 해당 텍스트와 (가능하면) 이미지 1개를 모델에 전달\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m3) 답변 생성\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m4) \"질문 / 대답\" 형태로 리턴\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 1) RAG 검색\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# relevant_items = simple_rag_search(question, data_list, top_k=top_k)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m relevant_items \u001b[38;5;241m=\u001b[39m \u001b[43mbm25_rag_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m relevant_items:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 검색된 결과가 없다면\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m질문 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m대답 : 관련된 자료(텍스트/이미지)를 찾지 못했습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36mbm25_rag_search\u001b[0;34m(question, data_list, top_k)\u001b[0m\n\u001b[1;32m     15\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_list]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 토큰화\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m tokenized_corpus \u001b[38;5;241m=\u001b[39m [word_tokenize(doc\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# BM25 객체 생성\u001b[39;00m\n\u001b[1;32m     21\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m BM25Okapi(tokenized_corpus)\n",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_list]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 토큰화\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m tokenized_corpus \u001b[38;5;241m=\u001b[39m [\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# BM25 객체 생성\u001b[39;00m\n\u001b[1;32m     21\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m BM25Okapi(tokenized_corpus)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/data/ephemeral/home/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "question_text = \"크래프톤의 발행 주식 수는?\"\n",
    "\n",
    "answer = rag_multimodal_qa(question_text, rag_data, top_k=3)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
